# Aimeå¤šæ™ºèƒ½ä½“æ¡†æ¶åŸå‹ - æµ‹è¯•ç”¨ä¾‹
import time
from typing import Dict, Any
from main import AimeSystem
from utils import logger
from config import config

class AimeTestSuite:
    """Aimeæµ‹è¯•å¥—ä»¶"""
    
    def __init__(self):
        self.test_results = []
        self.aime_system = None
    
    def run_all_tests(self) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸ§ª Aimeå¤šæ™ºèƒ½ä½“æ¡†æ¶æµ‹è¯•å¥—ä»¶")
        print("=" * 50)
        
        # åˆå§‹åŒ–ç³»ç»Ÿ
        try:
            print("ğŸ”§ åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ...")
            self.aime_system = AimeSystem()
            print("âœ… ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}
        
        # è¿è¡Œæµ‹è¯•ç”¨ä¾‹
        test_cases = [
            ("åŸºç¡€ç»„ä»¶æµ‹è¯•", self.test_basic_components),
            ("å•æ™ºèƒ½ä½“ä»»åŠ¡æµ‹è¯•", self.test_single_agent_tasks), 
            ("å¤šæ™ºèƒ½ä½“åä½œæµ‹è¯•", self.test_multi_agent_collaboration),
            ("åŠ¨æ€é‡è§„åˆ’æµ‹è¯•", self.test_dynamic_replanning),
            ("é”™è¯¯å¤„ç†æµ‹è¯•", self.test_error_handling),
            ("æ€§èƒ½åŸºå‡†æµ‹è¯•", self.test_performance_benchmark)
        ]
        
        for test_name, test_func in test_cases:
            print(f"\nğŸ” {test_name}...")
            try:
                result = test_func()
                self.test_results.append({
                    "name": test_name,
                    "success": result.get("success", False),
                    "details": result.get("details", ""),
                    "duration": result.get("duration", 0)
                })
                
                if result.get("success"):
                    print(f"âœ… {test_name} é€šè¿‡")
                else:
                    print(f"âŒ {test_name} å¤±è´¥: {result.get('details', '')}")
                    
            except Exception as e:
                print(f"âŒ {test_name} å¼‚å¸¸: {e}")
                self.test_results.append({
                    "name": test_name,
                    "success": False,
                    "details": str(e),
                    "duration": 0
                })
        
        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        return self.generate_test_report()
    
    def test_basic_components(self) -> Dict[str, Any]:
        """æµ‹è¯•åŸºç¡€ç»„ä»¶"""
        start_time = time.time()
        
        try:
            # æµ‹è¯•è§„åˆ’å™¨
            plan = self.aime_system.planner.plan("æµ‹è¯•ä»»åŠ¡è§„åˆ’åŠŸèƒ½")
            assert "tasks" in plan, "è§„åˆ’å™¨æœªç”Ÿæˆä»»åŠ¡åˆ—è¡¨"
            assert len(plan["tasks"]) > 0, "è§„åˆ’å™¨ç”Ÿæˆçš„ä»»åŠ¡åˆ—è¡¨ä¸ºç©º"
            
            # æµ‹è¯•å·¥å‚
            agent = self.aime_system.factory.create_actor("æµ‹è¯•æ™ºèƒ½ä½“åˆ›å»ºåŠŸèƒ½")
            assert agent is not None, "å·¥å‚æœªèƒ½åˆ›å»ºæ™ºèƒ½ä½“"
            assert hasattr(agent, "agent_id"), "æ™ºèƒ½ä½“ç¼ºå°‘IDå±æ€§"
            
            # æµ‹è¯•è¿›åº¦ç®¡ç†
            task_id = self.aime_system.progress_manager.create_task("æµ‹è¯•ä»»åŠ¡")
            assert task_id is not None, "è¿›åº¦ç®¡ç†å™¨æœªèƒ½åˆ›å»ºä»»åŠ¡"
            
            status = self.aime_system.progress_manager.get_task_status(task_id)
            assert status["status"] == "pending", "ä»»åŠ¡çŠ¶æ€ä¸æ­£ç¡®"
            
            return {
                "success": True,
                "details": "æ‰€æœ‰åŸºç¡€ç»„ä»¶åŠŸèƒ½æ­£å¸¸",
                "duration": time.time() - start_time
            }
            
        except Exception as e:
            return {
                "success": False,
                "details": str(e),
                "duration": time.time() - start_time
            }
    
    def test_single_agent_tasks(self) -> Dict[str, Any]:
        """æµ‹è¯•å•æ™ºèƒ½ä½“ä»»åŠ¡"""
        start_time = time.time()
        
        test_tasks = [
            {
                "goal": "è®¡ç®— 125 + 375 çš„ç»“æœ",
                "expected_type": "analyst",
                "should_contain": ["500", "è®¡ç®—"]
            },
            {
                "goal": "æ€»ç»“è¿™æ®µæ–‡æœ¬ï¼šäººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜ä¸–ç•Œ",
                "expected_type": "researcher", 
                "should_contain": ["äººå·¥æ™ºèƒ½", "æ€»ç»“"]
            },
            {
                "goal": "æ‰§è¡Œæ–‡ä»¶å¤‡ä»½æ“ä½œ",
                "expected_type": "executor",
                "should_contain": ["æ‰§è¡Œ", "æ–‡ä»¶"]
            }
        ]
        
        results = []
        
        for task in test_tasks:
            try:
                result = self.aime_system.execute_task(task["goal"])
                
                # æ£€æŸ¥ç»“æœ
                success = True
                details = []
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«é¢„æœŸå†…å®¹
                for expected in task["should_contain"]:
                    if expected not in result:
                        success = False
                        details.append(f"ç»“æœä¸­æœªæ‰¾åˆ°æœŸæœ›å†…å®¹: {expected}")
                
                results.append({
                    "task": task["goal"],
                    "success": success,
                    "details": details,
                    "result_length": len(result)
                })
                
            except Exception as e:
                results.append({
                    "task": task["goal"],
                    "success": False,
                    "details": [str(e)],
                    "result_length": 0
                })
        
        # è¯„ä¼°æ•´ä½“æˆåŠŸç‡
        success_count = sum(1 for r in results if r["success"])
        overall_success = success_count >= len(test_tasks) * 0.7  # 70%æˆåŠŸç‡
        
        return {
            "success": overall_success,
            "details": f"å•æ™ºèƒ½ä½“ä»»åŠ¡æˆåŠŸç‡: {success_count}/{len(test_tasks)}",
            "duration": time.time() - start_time,
            "task_results": results
        }
    
    def test_multi_agent_collaboration(self) -> Dict[str, Any]:
        """æµ‹è¯•å¤šæ™ºèƒ½ä½“åä½œ"""
        start_time = time.time()
        
        try:
            goal = "ç ”ç©¶äººå·¥æ™ºèƒ½åœ¨æ•™è‚²é¢†åŸŸçš„åº”ç”¨ï¼Œåˆ†æå…¶ä¼˜åŠ¿ï¼Œå¹¶ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"
            result = self.aime_system.execute_multi_agent_task(goal)
            
            # æ£€æŸ¥åä½œç»“æœ
            success_indicators = [
                "ç ”ç©¶" in result or "åˆ†æ" in result,
                "ä¼˜åŠ¿" in result or "åº”ç”¨" in result,
                "æŠ¥å‘Š" in result or "æ€»ç»“" in result,
                len(result) > 100  # ç»“æœåº”è¯¥æœ‰è¶³å¤Ÿçš„å†…å®¹
            ]
            
            success = sum(success_indicators) >= 3
            
            return {
                "success": success,
                "details": f"åä½œç»“æœè´¨é‡è¯„åˆ†: {sum(success_indicators)}/4",
                "duration": time.time() - start_time,
                "result_length": len(result)
            }
            
        except Exception as e:
            return {
                "success": False,
                "details": str(e),
                "duration": time.time() - start_time
            }
    
    def test_dynamic_replanning(self) -> Dict[str, Any]:
        """æµ‹è¯•åŠ¨æ€é‡è§„åˆ’"""
        start_time = time.time()
        
        try:
            # ç¬¬ä¸€æ¬¡è§„åˆ’
            initial_goal = "åˆ†æé”€å”®æ•°æ®"
            initial_plan = self.aime_system.planner.plan(initial_goal)
            
            # æ¨¡æ‹Ÿæ‰§è¡Œåé¦ˆ
            feedback = "æ•°æ®æ ¼å¼æœ‰é—®é¢˜ï¼Œéœ€è¦å…ˆè¿›è¡Œæ•°æ®æ¸…ç†"
            current_state = "å·²è·å–åŸå§‹æ•°æ®æ–‡ä»¶"
            
            # é‡æ–°è§„åˆ’
            new_plan = self.aime_system.planner.plan(
                initial_goal, 
                current_state=current_state, 
                feedback=feedback
            )
            
            # æ£€æŸ¥é‡è§„åˆ’ç»“æœ
            success_checks = [
                len(new_plan.get("tasks", [])) > 0,
                "æ¸…ç†" in str(new_plan) or "æ ¼å¼" in str(new_plan),
                new_plan != initial_plan  # åº”è¯¥æœ‰æ‰€ä¸åŒ
            ]
            
            success = all(success_checks)
            
            return {
                "success": success,
                "details": "åŠ¨æ€é‡è§„åˆ’åŠŸèƒ½æ­£å¸¸" if success else "é‡è§„åˆ’æœªèƒ½æ­£ç¡®å“åº”åé¦ˆ",
                "duration": time.time() - start_time,
                "initial_tasks": len(initial_plan.get("tasks", [])),
                "new_tasks": len(new_plan.get("tasks", []))
            }
            
        except Exception as e:
            return {
                "success": False,
                "details": str(e),
                "duration": time.time() - start_time
            }
    
    def test_error_handling(self) -> Dict[str, Any]:
        """æµ‹è¯•é”™è¯¯å¤„ç†"""
        start_time = time.time()
        
        error_scenarios = [
            {
                "name": "ç©ºä»»åŠ¡æè¿°",
                "goal": "",
                "should_handle": True
            },
            {
                "name": "è¿‡é•¿ä»»åŠ¡æè¿°", 
                "goal": "æµ‹è¯•" * 1000,
                "should_handle": True
            },
            {
                "name": "ç‰¹æ®Šå­—ç¬¦ä»»åŠ¡",
                "goal": "æµ‹è¯•!@#$%^&*()[]{}|\\:;\"'<>?/.,",
                "should_handle": True
            }
        ]
        
        handled_correctly = 0
        
        for scenario in error_scenarios:
            try:
                result = self.aime_system.execute_task(scenario["goal"])
                
                # æ£€æŸ¥æ˜¯å¦ä¼˜é›…å¤„ç†
                if result and not result.startswith("Traceback"):
                    handled_correctly += 1
                    
            except Exception:
                # å¼‚å¸¸ä¹Ÿç®—æ˜¯å¤„ç†äº†ï¼Œåªè¦ä¸å´©æºƒ
                handled_correctly += 1
        
        success = handled_correctly >= len(error_scenarios) * 0.8
        
        return {
            "success": success,
            "details": f"é”™è¯¯å¤„ç†æˆåŠŸç‡: {handled_correctly}/{len(error_scenarios)}",
            "duration": time.time() - start_time
        }
    
    def test_performance_benchmark(self) -> Dict[str, Any]:
        """æµ‹è¯•æ€§èƒ½åŸºå‡†"""
        start_time = time.time()
        
        # æ€§èƒ½æµ‹è¯•ç”¨ä¾‹
        performance_tasks = [
            "ç®€å•è®¡ç®—: 2 + 2",
            "æ–‡æœ¬åˆ†æ: åˆ†æè¿™å¥è¯çš„æƒ…æ„Ÿ",
            "ä¿¡æ¯æ£€ç´¢: æœç´¢äººå·¥æ™ºèƒ½ç›¸å…³ä¿¡æ¯"
        ]
        
        execution_times = []
        success_count = 0
        
        for task in performance_tasks:
            task_start = time.time()
            try:
                result = self.aime_system.execute_task(task)
                task_duration = time.time() - task_start
                execution_times.append(task_duration)
                
                if result and len(result) > 10:  # æœ‰æ•ˆç»“æœ
                    success_count += 1
                    
            except Exception:
                execution_times.append(config.TIMEOUT_SECONDS)  # è¶…æ—¶ä½œä¸ºæœ€å¤§æ—¶é—´
        
        # æ€§èƒ½æŒ‡æ ‡
        avg_time = sum(execution_times) / len(execution_times) if execution_times else 0
        max_time = max(execution_times) if execution_times else 0
        
        # æ€§èƒ½è¯„ä¼°
        performance_good = (
            avg_time < 30.0 and  # å¹³å‡æ‰§è¡Œæ—¶é—´ < 30ç§’
            max_time < 60.0 and  # æœ€å¤§æ‰§è¡Œæ—¶é—´ < 60ç§’
            success_count >= len(performance_tasks) * 0.8  # 80%æˆåŠŸç‡
        )
        
        return {
            "success": performance_good,
            "details": f"å¹³å‡æ‰§è¡Œæ—¶é—´: {avg_time:.2f}ç§’, æˆåŠŸç‡: {success_count}/{len(performance_tasks)}",
            "duration": time.time() - start_time,
            "avg_execution_time": avg_time,
            "max_execution_time": max_time,
            "success_rate": success_count / len(performance_tasks)
        }
    
    def generate_test_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        total_tests = len(self.test_results)
        passed_tests = sum(1 for result in self.test_results if result["success"])
        total_duration = sum(result["duration"] for result in self.test_results)
        
        print(f"\nğŸ“Š æµ‹è¯•æŠ¥å‘Š")
        print("=" * 50)
        print(f"æ€»æµ‹è¯•æ•°: {total_tests}")
        print(f"é€šè¿‡æ•°: {passed_tests}")
        print(f"å¤±è´¥æ•°: {total_tests - passed_tests}")
        print(f"æˆåŠŸç‡: {passed_tests/total_tests:.1%}")
        print(f"æ€»è€—æ—¶: {total_duration:.2f}ç§’")
        
        # è¯¦ç»†ç»“æœ
        print(f"\nğŸ“‹ è¯¦ç»†ç»“æœ:")
        for result in self.test_results:
            status = "âœ…" if result["success"] else "âŒ"
            print(f"  {status} {result['name']} ({result['duration']:.2f}s)")
            if not result["success"]:
                print(f"    é”™è¯¯: {result['details']}")
        
        # ç³»ç»ŸçŠ¶æ€
        if self.aime_system:
            print(f"\nğŸ¤– ç³»ç»ŸçŠ¶æ€:")
            status = self.aime_system.get_status()
            print(f"  è¿è¡Œæ—¶é—´: {status['uptime']:.2f}ç§’")
            print(f"  æ€»ä»»åŠ¡æ•°: {status['tasks']['total_tasks']}")
            print(f"  å®Œæˆä»»åŠ¡æ•°: {status['tasks']['completed_tasks']}")
            print(f"  æ´»è·ƒæ™ºèƒ½ä½“: {status['agents']['total_created']}")
        
        return {
            "total_tests": total_tests,
            "passed_tests": passed_tests,
            "success_rate": passed_tests / total_tests,
            "total_duration": total_duration,
            "test_results": self.test_results,
            "overall_success": passed_tests >= total_tests * 0.7  # 70%é€šè¿‡ç‡
        }

def run_quick_test():
    """å¿«é€ŸéªŒè¯æµ‹è¯•"""
    print("ğŸš€ Aimeå¿«é€ŸéªŒè¯æµ‹è¯•")
    print("=" * 30)
    
    try:
        # åˆå§‹åŒ–ç³»ç»Ÿ
        aime = AimeSystem()
        
        # æµ‹è¯•åŸºç¡€åŠŸèƒ½
        print("1. æµ‹è¯•ç®€å•ä»»åŠ¡...")
        result1 = aime.execute_task("è®¡ç®— 10 + 20 çš„ç»“æœ")
        print(f"   ç»“æœ: {result1[:100]}...")
        
        print("2. æµ‹è¯•æ–‡æœ¬å¤„ç†...")
        result2 = aime.execute_task("åˆ†æè¿™æ®µæ–‡æœ¬çš„ä¸»è¦å†…å®¹ï¼šäººå·¥æ™ºèƒ½æ­£åœ¨å¿«é€Ÿå‘å±•")
        print(f"   ç»“æœ: {result2[:100]}...")
        
        print("3. æµ‹è¯•å¤šæ™ºèƒ½ä½“åä½œ...")
        result3 = aime.execute_multi_agent_task("ç ”ç©¶æœºå™¨å­¦ä¹ çš„åº”ç”¨å‰æ™¯")
        print(f"   ç»“æœ: {result3[:100]}...")
        
        # æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
        print("4. ç³»ç»ŸçŠ¶æ€...")
        status = aime.get_status()
        print(f"   ä»»åŠ¡å®Œæˆç‡: {status['tasks']['completion_rate']:.1%}")
        print(f"   åˆ›å»ºæ™ºèƒ½ä½“æ•°: {status['agents']['total_created']}")
        
        print("\nâœ… å¿«é€ŸéªŒè¯æµ‹è¯•å®Œæˆï¼")
        return True
        
    except Exception as e:
        print(f"\nâŒ å¿«é€ŸéªŒè¯æµ‹è¯•å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "quick":
        # å¿«é€Ÿæµ‹è¯•
        run_quick_test()
    else:
        # å®Œæ•´æµ‹è¯•å¥—ä»¶
        test_suite = AimeTestSuite()
        report = test_suite.run_all_tests()
        
        if report.get("overall_success"):
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•åŸºæœ¬é€šè¿‡ï¼Œç³»ç»Ÿå¯ä»¥æ­£å¸¸ä½¿ç”¨ï¼")
        else:
            print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œå»ºè®®æ£€æŸ¥é…ç½®å’Œä¾èµ–ã€‚")
        
        print(f"\næœ€ç»ˆè¯„åˆ†: {report['success_rate']:.1%}")